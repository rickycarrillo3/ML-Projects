{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsMVcXJmadCunAfOhwoocx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickycarrillo3/ML-Projects/blob/main/Monte_Carlo_Simulations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome back to these demos ! Today, we will be exploring the simple but quite useful **Monte Carlo Simulations**. Their purpose is to estimate some probability of interest by iteratively taking samples from the sample space. The main idea is that given a. large number of iterations, or trials, the values of interest will come close to the probabilistic truth. We will delve into some simple examples and conclude with a more realistic application of this estimation method."
      ],
      "metadata": {
        "id": "VAspIrfqbIrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hr_cpnivaexP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by going through a simple, well-known example: rolling dice. Our sample space will consist of outcomes of the form $(r_1, r_2)$ where $r_1$ is the result of the first roll, and $r_2$ is the result of the second roll. We will simulate rolling two dice in order to estimate the mean of their sum, the variance of their sum, and the probabilities of each outcome.\n",
        "\n",
        "We will discuss the theory behind the computation of the true values, but it is only included to be mathematically rigorous. If you want, you could just skip the following paragraph.\n",
        "\n",
        "Now, using basic probability theory, we can estimate the true value of each of these. Let $X$ be the random variable with value equal to the sum of the dice rolls. Then, $X = R_1 + R_2$ where $R_1$ and $R_2$ are random variables themselves, each with value equal to $r_1$ and $r_2$ respectively.\n",
        "\n",
        "Because of linearity of expectation, we have\n",
        "\n",
        "$\\mathbb{E}(X) = \\mathbb{E}(R_1 + R_2) = \\mathbb{E}(R_1) + \\mathbb{E}(R_2) = 3.5 + 3.5 = 7$\n",
        "\n",
        "Because $R_1$ and $R_2$ are independent, we have\n",
        "\n",
        "$\\text{Var}(X) = \\text{Var}(R_1) + \\text{Var}(R_2) = \\frac{35}{6} \\approx 5.833$\n",
        "\n",
        "Finally, we also have that the probability of each outcome should be $\\frac{1}{36} \\approx 0.0278$."
      ],
      "metadata": {
        "id": "Il63OxAOc_ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDiceSim:\n",
        "  def __init__(self, iters=1000):\n",
        "    self.iters = iters\n",
        "    self.frequencies_dict = {}\n",
        "    # Set up the possible outcomes\n",
        "    for a in range(1, 7):\n",
        "      for b in range(1,7):\n",
        "        self.frequencies_dict[(a,b)] = 0\n",
        "\n",
        "  def run_montecarlo(self):\n",
        "    for iter in range(self.iters):\n",
        "      value_1 = random.randint(1, 6)\n",
        "      value_2 = random.randint(1,6)\n",
        "      if iter % round(self.iters / 5) == 0:\n",
        "        print(f\"Roll # {iter}: Value 1: {value_1}, Value 2: {value_2}\")\n",
        "      # Add to the frequency list\n",
        "      self.frequencies_dict[(value_1, value_2)] += 1\n",
        "\n",
        "  def report_stats(self, stats_to_report={'MEAN', 'VARIANCE', 'PROBS'}):\n",
        "    \"\"\"\n",
        "    Given one of the folllowing options,\n",
        "    it reports the desired stats:\n",
        "\n",
        "    - MEAN: The mean of the sum of values of the rolls\n",
        "\n",
        "    - VARIANCE: The variance of the sum of the values of the rolls\n",
        "\n",
        "    - PROBS: The probabilities of each outcome\n",
        "\n",
        "    By default, reports all three. Also reports the\n",
        "    true values (independent of the instance of the\n",
        "    experiment)\n",
        "\n",
        "    stats_to_report: A set with the options\n",
        "    \"\"\"\n",
        "\n",
        "    if 'MEAN' in stats_to_report or 'VARIANCE' in stats_to_report:\n",
        "    # Since we need to compute the mean for the variance, we do it regardless\n",
        "    # Compute the mean\n",
        "      total_sum = 0\n",
        "      for outcome, freq in self.frequencies_dict.items():\n",
        "        outcome_sum = outcome[0] + outcome[1]\n",
        "        total_sum += outcome_sum * freq\n",
        "\n",
        "      mean = total_sum / self.iters\n",
        "      if 'MEAN' in stats_to_report:\n",
        "        print(f\"Mean: {mean: .3f} | Expected value: 7\\n\")\n",
        "\n",
        "      if 'VARIANCE' in stats_to_report:\n",
        "        var_sum = 0\n",
        "        for outcome, freq in self.frequencies_dict.items():\n",
        "          intermediate_sum = ((outcome[0] + outcome[1]) - mean) ** 2\n",
        "          var_sum += intermediate_sum * freq\n",
        "\n",
        "        var = var_sum / self.iters\n",
        "        print(f\"Variance: {var: .3f} | True Variance: 35/6\\n\")\n",
        "\n",
        "    if 'PROBS' in stats_to_report:\n",
        "      probs = {}\n",
        "      for a in range(1,7):\n",
        "        for b in range(1,7):\n",
        "          probs[(a,b)] = self.frequencies_dict[(a,b)] / self.iters\n",
        "\n",
        "      print(f\"Probabilities: {probs} | Each outcome should have a probability of 1/36\")"
      ],
      "metadata": {
        "id": "Z7I2i9ODb4v2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = SimpleDiceSim()\n",
        "long_experiment = SimpleDiceSim(50000)\n",
        "\n",
        "# Short experiment results\n",
        "experiment.run_montecarlo()\n",
        "experiment.report_stats()\n",
        "print(\"--------------------------------------\")\n",
        "\n",
        "# Long experiment results\n",
        "long_experiment.run_montecarlo()\n",
        "long_experiment.report_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcPL1G2YicCt",
        "outputId": "7cd14bd8-507f-4f9e-c416-3972ee37c2e6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roll # 0: Value 1: 2, Value 2: 2\n",
            "Roll # 200: Value 1: 3, Value 2: 5\n",
            "Roll # 400: Value 1: 5, Value 2: 3\n",
            "Roll # 600: Value 1: 6, Value 2: 2\n",
            "Roll # 800: Value 1: 2, Value 2: 4\n",
            "Mean:  6.984 | Expected value: 7\n",
            "\n",
            "Variance:  5.438 | True Variance: 35/6\n",
            "\n",
            "Probabilities: {(1, 1): 0.028, (1, 2): 0.021, (1, 3): 0.032, (1, 4): 0.024, (1, 5): 0.014, (1, 6): 0.026, (2, 1): 0.025, (2, 2): 0.023, (2, 3): 0.037, (2, 4): 0.029, (2, 5): 0.031, (2, 6): 0.023, (3, 1): 0.023, (3, 2): 0.028, (3, 3): 0.034, (3, 4): 0.026, (3, 5): 0.034, (3, 6): 0.022, (4, 1): 0.03, (4, 2): 0.022, (4, 3): 0.031, (4, 4): 0.028, (4, 5): 0.037, (4, 6): 0.017, (5, 1): 0.041, (5, 2): 0.026, (5, 3): 0.031, (5, 4): 0.022, (5, 5): 0.03, (5, 6): 0.027, (6, 1): 0.04, (6, 2): 0.029, (6, 3): 0.037, (6, 4): 0.021, (6, 5): 0.028, (6, 6): 0.023} | Each outcome should have a probability of 1/36\n",
            "--------------------------------------\n",
            "Roll # 0: Value 1: 2, Value 2: 5\n",
            "Roll # 10000: Value 1: 6, Value 2: 1\n",
            "Roll # 20000: Value 1: 2, Value 2: 5\n",
            "Roll # 30000: Value 1: 5, Value 2: 1\n",
            "Roll # 40000: Value 1: 6, Value 2: 3\n",
            "Mean:  6.977 | Expected value: 7\n",
            "\n",
            "Variance:  5.869 | True Variance: 35/6\n",
            "\n",
            "Probabilities: {(1, 1): 0.02912, (1, 2): 0.02828, (1, 3): 0.02718, (1, 4): 0.02818, (1, 5): 0.02722, (1, 6): 0.0265, (2, 1): 0.02806, (2, 2): 0.02884, (2, 3): 0.02788, (2, 4): 0.02766, (2, 5): 0.02746, (2, 6): 0.02756, (3, 1): 0.02776, (3, 2): 0.02896, (3, 3): 0.02764, (3, 4): 0.02742, (3, 5): 0.0272, (3, 6): 0.02776, (4, 1): 0.02862, (4, 2): 0.02818, (4, 3): 0.0282, (4, 4): 0.02808, (4, 5): 0.02754, (4, 6): 0.0267, (5, 1): 0.02758, (5, 2): 0.02832, (5, 3): 0.02856, (5, 4): 0.02782, (5, 5): 0.0275, (5, 6): 0.0273, (6, 1): 0.02676, (6, 2): 0.02688, (6, 3): 0.02748, (6, 4): 0.02868, (6, 5): 0.02762, (6, 6): 0.0275} | Each outcome should have a probability of 1/36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example dealt with a very simple scenario. However, we can use Monte Carlo simulations to explore more intricate scenarios. In our case, we will use the simulations to estimate financial losses for an **ETF** of interest.\n",
        "\n",
        "We will build a predictive model of the **VaR** (Value at Risk) and **CVaR** (Conditional Value at Risk) of the Vanguard S&P 500 ETF (VOO) These two metrics both measure losses in the \"worst-case\" scenarios when investing.\n",
        "\n",
        "Feel free to learn more here: https://www.investopedia.com/terms/c/conditional_value_at_risk.asp"
      ],
      "metadata": {
        "id": "2IgV5Gg3sSy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Before we go on, follow the next steps:**\n",
        "\n",
        "**1) Go to https://www.marketwatch.com/ and look for the VOO ETF page.**\n",
        "\n",
        "**2) Go to the bottom of the VOO page and download the csv with the historical daily prices.**\n",
        "\n",
        "**3) Upload the CSV to Google Colab.**"
      ],
      "metadata": {
        "id": "ahzoIs_tkUUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"Download Data - FUND_US_ARCX_VOO-2.csv\" # Enter the name of your downloaded file here\n",
        "df = pd.read_csv(f\"/content/{filename}\")\n",
        "# Print first ten rows\n",
        "print(df.head(10))\n",
        "# Sort by date\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
        "df = df.sort_values(by='Date')\n",
        "print(df.head())\n",
        "\n",
        "print(\"--------------------------------------------------\")\n",
        "\n",
        "only_closing_df = df[['Close']]\n",
        "# Print first ten rows\n",
        "print(only_closing_df.head(10))\n",
        "print(f\"Rows: {only_closing_df.shape[0]}\") # Should be around 250"
      ],
      "metadata": {
        "id": "72W2hl3JixtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7204355-7038-48f8-a15e-8c3b309c4786"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Date    Open    High     Low   Close      Volume\n",
            "0  12/24/2025  632.67  635.32  632.54  634.78   3,275,186\n",
            "1  12/23/2025  628.94  632.88  628.92  632.67  13,798,470\n",
            "2  12/22/2025  628.97  630.27  627.80  629.73   9,850,052\n",
            "3  12/19/2025  623.98  628.13  623.86  627.56  10,487,010\n",
            "4  12/18/2025  623.05  625.94  620.57  622.01  37,062,391\n",
            "5  12/17/2025  625.19  625.64  617.16  617.35  21,356,910\n",
            "6  12/16/2025  624.55  626.22  620.65  624.21  15,819,620\n",
            "7  12/15/2025  630.56  630.56  624.57  625.96  11,337,200\n",
            "8  12/12/2025  632.80  633.43  624.48  626.87   8,534,727\n",
            "9  12/11/2025  630.00  633.87  627.27  633.71  33,921,039\n",
            "          Date    Open    High     Low   Close     Volume\n",
            "249 2024-12-26  551.20  553.97  549.92  552.81  4,496,268\n",
            "248 2024-12-27  549.37  549.62  543.20  547.08  7,077,135\n",
            "247 2024-12-30  540.56  544.09  537.40  540.99  6,505,089\n",
            "246 2024-12-31  542.45  543.07  537.40  538.81  6,040,750\n",
            "245 2025-01-02  542.02  543.54  533.80  537.46  7,142,698\n",
            "--------------------------------------------------\n",
            "      Close\n",
            "249  552.81\n",
            "248  547.08\n",
            "247  540.99\n",
            "246  538.81\n",
            "245  537.46\n",
            "244  544.40\n",
            "243  547.57\n",
            "242  541.41\n",
            "241  542.14\n",
            "240  533.89\n",
            "Rows: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the closing prices in our return calculations. Feel free to edit the code above and try using some other columns."
      ],
      "metadata": {
        "id": "0h7MkKYDm42L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add shifted copy for simplicity of calculation\n",
        "shifted_close_df = df['Close'].shift(periods=1)\n",
        "# # Insert an additional closing column\n",
        "only_closing_df.insert(1, 'Shifted Close', shifted_close_df)\n",
        "print(only_closing_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaZYvJRYohbk",
        "outputId": "8cf46037-2b41-4122-e701-8fccc8fd285f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Close  Shifted Close\n",
            "249  552.81            NaN\n",
            "248  547.08         552.81\n",
            "247  540.99         547.08\n",
            "246  538.81         540.99\n",
            "245  537.46         538.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will compute the returns using the following formula.\n",
        "\n",
        "$r_t = \\log\\left(\\frac{P_t}{P_{t-1}}\\right)$\n",
        "\n",
        "One of the reasons behind using $\\log$ returns instead of simple returns is the fact that increases and decreases in price are symmetric in terms of returns.\n",
        "\n",
        "For instance, suppose we have \\$10 and we have a \\$1 increase followed by a \\$1 decrease. This is a 10% increase from the base followed by a 9.09% ($\\frac{1}{11} \\cdot 100$) decrease in simple returns.\n",
        "\n",
        "In the other hand, using log returns we have that the first change is $\\log(\\frac{11}{10})$ and the second change is $\\log(\\frac{10}{11})$, which completely cancel out, as desired."
      ],
      "metadata": {
        "id": "XA8Uiid6ujRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make new data frames with returns\n",
        "return_df = pd.DataFrame()\n",
        "return_df['Returns'] = np.log(only_closing_df['Close'] / only_closing_df['Shifted Close'])\n",
        "print(return_df.head(20))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-tquXcXsjfvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f9e7be-e454-4c14-b4f7-b9f3c6670031"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Returns\n",
            "249       NaN\n",
            "248 -0.010419\n",
            "247 -0.011194\n",
            "246 -0.004038\n",
            "245 -0.002509\n",
            "244  0.012830\n",
            "243  0.005806\n",
            "242 -0.011313\n",
            "241  0.001347\n",
            "240 -0.015334\n",
            "239  0.001292\n",
            "238  0.001271\n",
            "237  0.018125\n",
            "236 -0.001487\n",
            "235  0.009546\n",
            "234  0.009059\n",
            "233  0.005665\n",
            "232  0.005526\n",
            "231 -0.003019\n",
            "230 -0.014015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some statistics\n",
        "return_mean = return_df.mean()\n",
        "print(f\"Mean return over last year: {return_mean.item(): .5f}\\n\")\n",
        "return_std = return_df.std()\n",
        "print(f\"Standard deviation of the return: {return_std.item(): .5f}\\n\")"
      ],
      "metadata": {
        "id": "G2G08SmWp4DJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612dcf1e-3879-4b33-a439-4eae10e20ed5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean return over last year:  0.00056\n",
            "\n",
            "Standard deviation of the return:  0.01167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphic of the returns (You'll see the motivation behind using a Normal Distribution)\n",
        "pd.DataFrame.hist(return_df[['Returns']], bins=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "AbNnceQjEqd4",
        "outputId": "d77230f5-5f02-4067-cb1c-e2b835f156e0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'Returns'}>]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can go ahead and get rid of the top row, since it is undefined or NaN by our formulation. Now, we will start our Monte Carlo simulation step. In order to model future returns, we must assume a distribution for the returns. In other words, we must make an assumption as to how returns behave.\n",
        "\n",
        "As a baseline, we will build a model with returns following a Normal distribution, i.e, $\\mathcal{N}(\\mu, \\sigma^2)$, where $\\mu$ is the sample mean, and $\\sigma^2$ is the sample variance. In this model, daily returns will be independent draws from this distribution. This setup will serve as a solid baseline experiment.\n",
        "\n",
        "We have already computed these two metrics, so we can fully specify the distribution we will use.\n",
        "\n",
        "Before we move on, it is important that we describe the structure of the Monte Carlo simulation at hand since this one will be more complex than the dice rolling scenario.\n",
        "\n",
        "**VaR and CVaR Monte Carlo Simulation Structure**\n",
        "\n",
        "We will define $I$, the number of total iterations and $H$, the length of our horizon, i.e, the number of days for each iteration.\n",
        "\n",
        "In each iteration, we will simulate returns from $H$ consecutive days. We will sample $H$ times from the normal distribution we defined above, and we will add these returns to obtain a total iteration return.\n",
        "\n",
        "\n",
        "$r_1 + r_2 + ... + r_H = \\sum_{i=1}^H \\log\\left(\\frac{P_i}{P_{i-1}}\\right) = \\log\\left(\\frac{P_H}{P_0}\\right) = \\text{Return of investment with respect to the first day}$\n",
        "\n",
        "We will then assume $P_0 = 1$ in order to get $P_H$ as a percentage by using the exponential function.\n",
        "\n",
        "**NOTE**: this is just normalization, so it will not affect the correctness of our model by imposing additional assumptions. In other words, we are only setting the scale by fixing $P_0$ to the value we want, but it does not affect the model's core assumptions.\n",
        "\n",
        "Overall, we will compute this quantity $I$ times, i.e, run this simulation $I$ times.\n",
        "\n"
      ],
      "metadata": {
        "id": "YF5Htof3T3lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Normal_Var_MC:\n",
        "\n",
        "  def __init__(self, mu, std, horizon_days=10, iters=1000):\n",
        "    self.mu = mu\n",
        "    self.std = std\n",
        "    self.horizon_days = horizon_days\n",
        "    self.iters = iters\n",
        "    self.return_values = None\n",
        "\n",
        "  def run_simulation(self):\n",
        "    self.return_values = []\n",
        "    for i in range(self.iters):\n",
        "      # Sample from given distribution the number of days given\n",
        "      total_sample_return = 0\n",
        "      for _ in range(self.horizon_days):\n",
        "        sample = np.random.normal(self.mu, self.std)\n",
        "        total_sample_return += sample\n",
        "      # Compute final return value (including the compounding)\n",
        "      end_return_value = np.exp(total_sample_return)\n",
        "      self.return_values.append(end_return_value.item())\n",
        "      if i % (self.iters / 5) == 0:\n",
        "        print(f\"Iteration: {i} | Simulated end return: {end_return_value.item(): .3f}\")\n",
        "\n",
        "\n",
        "  def report_mean(self):\n",
        "    if self.return_values:\n",
        "      mean = sum(self.return_values) / len(self.return_values)\n",
        "      print(f\"Mean: {mean}\")\n",
        "    else:\n",
        "      print(\"Simulation not run yet\")\n",
        "\n",
        "\n",
        "  def compute_loss(self, df=False):\n",
        "    if self.return_values:\n",
        "      loss_values = [1 - a for a in self.return_values]\n",
        "      return loss_values # For future edits return as a pandas Dataframe\n",
        "    else:\n",
        "      print(\"Simulation not run yet\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oe3qwNptuoQe"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to compute the losses, we will take difference between $P_0$ and $P_H$. That is,\n",
        "\n",
        "$L_H = P_0 - P_H = 1 - P_H$\n",
        "\n",
        "Thus if the loss is $0.03$, the return of our investment was $-3\\%$, i.e, we lost 3% of our investment."
      ],
      "metadata": {
        "id": "bhXZjTlF4v5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_montecarlo = Normal_Var_MC(return_mean, return_std)\n",
        "normal_montecarlo.run_simulation()\n",
        "# Get return and loss\n",
        "returns = normal_montecarlo.return_values\n",
        "losses = normal_montecarlo.compute_loss()\n",
        "# print(returns)\n",
        "# print(losses)"
      ],
      "metadata": {
        "id": "V12ziw2_UsrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d5dfc3-0bfb-4640-fa13-5f003daa9b02"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 | Simulated end return:  0.991\n",
            "Iteration: 200 | Simulated end return:  0.980\n",
            "Iteration: 400 | Simulated end return:  1.019\n",
            "Iteration: 600 | Simulated end return:  0.998\n",
            "Iteration: 800 | Simulated end return:  0.970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Value At Risk and Conditional Value at Risk\n",
        "def compute_var_and_cvar(losses, alpha=0.95, provide_values=False):\n",
        "  # Get threshold quantity (VaR)\n",
        "  value_at_risk = np.quantile(losses, alpha)\n",
        "  losses_filtered = []\n",
        "  for a in losses:\n",
        "    if a > value_at_risk:\n",
        "      losses_filtered.append(a)\n",
        "  # Compute mean\n",
        "  cvar= sum(losses_filtered) / len(losses_filtered)\n",
        "  if provide_values:\n",
        "    return value_at_risk, cvar, losses_filtered\n",
        "  else:\n",
        "    return value_at_risk, cvar\n",
        "\n",
        "### Results #####\n",
        "our_var, our_cvar = compute_var_and_cvar(losses)\n",
        "print(f\"Value at Risk at 95% confidence level: {our_var: .3f}\")\n",
        "print(f\"Conditional Value at Risk at 95% confidence level: {our_cvar: .3f}\")\n",
        "print(\"----------------------------------------\")\n",
        "our_var_99, our_cvar_99 = compute_var_and_cvar(losses, alpha=0.99)\n",
        "print(f\"Value at Risk at 99% confidence level: {our_var_99: .3f}\")\n",
        "print(f\"Conditional Value at Risk at 99% confidence level: {our_cvar_99: .3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5q_vRvrCc-1",
        "outputId": "de1ab5b7-7eef-49f2-ee5a-c13ac35e7633"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value at Risk at 95% confidence level:  0.051\n",
            "Conditional Value at Risk at 95% confidence level:  0.064\n",
            "----------------------------------------\n",
            "Value at Risk at 99% confidence level:  0.070\n",
            "Conditional Value at Risk at 99% confidence level:  0.084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do these values mean? Suppose VaR is 0.055 and CVaR is 0.071 at a 95% confidence level for both.\n",
        "\n",
        "Given all of the losses, the Value at Risk metric tells us that in 95% of the losses, we do not lose more than 5.5% of our investment. Now, given that we lost more than 5.5%, the Conditional Value at Risk metric tells us that the average loss is 9.2%."
      ],
      "metadata": {
        "id": "BF-OV7wYybNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This concludes this demo, but feel free to experiment with the distribution used for the VaR and CVaR Mc simulation. One natural step is to see how results would differ if instead of a normal distribution, we used a Student's t-distribution**"
      ],
      "metadata": {
        "id": "Ra9_6TiE0ePo"
      }
    }
  ]
}